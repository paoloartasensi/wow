{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC TESTpress with Chat GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scelta automatica del Path locale tra \"paoloartasensi\" o \"lorenzobassetti\"\n",
    "path = '/Users/paoloartasensi/Python_Scripts/artabax/'\n",
    "isdir = os.path.isdir(path)\n",
    "if isdir == True:\n",
    "    path = '/Users/paoloartasensi/Python_Scripts/artabax/'\n",
    "else:\n",
    "    path = '/Users/lorenzobassetti/Dropbox/Quant/Python_DEV/artabax/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILE NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## COPY AND PAST RELATIVE PATH HERE\" ###############\n",
    "\n",
    "relative_file_name = 'Gdrive_csv/20221228_1245PM_biceps.csv'\n",
    "\n",
    "################################################################\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(path+relative_file_name)\n",
    "# Extract the substring [relative_name_file] from the string\n",
    "string = relative_file_name\n",
    "start_index = string.find('Gdrive_csv/') + len('Gdrive_csv/')\n",
    "end_index = string.find('.csv')\n",
    "substring = string[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1366 entries, 0 to 1365\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  1366 non-null   int64  \n",
      " 1   ax         1366 non-null   float64\n",
      " 2   ay         1366 non-null   float64\n",
      " 3   az         1366 non-null   float64\n",
      " 4   gx         1366 non-null   float64\n",
      " 5   gy         1366 non-null   float64\n",
      " 6   gz         1366 non-null   float64\n",
      " 7   pitch      1366 non-null   float64\n",
      " 8   roll       1366 non-null   float64\n",
      " 9   BAR        1366 non-null   float64\n",
      " 10  totacc     1366 non-null   float64\n",
      " 11  status     1366 non-null   int64  \n",
      " 12  mov        0 non-null      float64\n",
      " 13  prob       1366 non-null   int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 149.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.13%\n",
      "Accuracy: 0.8613138686131386\n",
      "Precision: 0.78125\n",
      "Recall: 0.6756756756756757\n",
      "F1: 2.027027027027027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Select the columns containing the features\n",
    "X = df[['ax', 'ay', 'az', 'gx', 'gy', 'gz','pitch','roll', 'BAR','totacc' ]]\n",
    "\n",
    "# Select the column containing the labels (0 for non-rep, 1 for rep)\n",
    "y = df['status']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "# Train a random forest classifier on the training data\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "F1 = 2 * (precision)*(recall)/(precision)+(recall)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print(\"F1:\", F1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.77%\n",
      "Accuracy: 0.8576642335766423\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.546875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \"Weights\" (coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the weights (coefficients) for each feature with their corresponding labels (feature names)\n",
    "#for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    #print('{}: {}'.format(feature, coef))\n",
    "#print(\"b0\",model.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST FALSE/TRUE positive FALSE/TRUE negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>BAR</th>\n",
       "      <th>totacc</th>\n",
       "      <th>status</th>\n",
       "      <th>mov</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.366000e+03</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.672228e+12</td>\n",
       "      <td>-2.194387</td>\n",
       "      <td>-3.651228</td>\n",
       "      <td>-1.438232</td>\n",
       "      <td>-3.102188</td>\n",
       "      <td>8.506637</td>\n",
       "      <td>5.378622</td>\n",
       "      <td>22.621247</td>\n",
       "      <td>-2.271998</td>\n",
       "      <td>0.023516</td>\n",
       "      <td>9.977873</td>\n",
       "      <td>0.232796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.215225e+04</td>\n",
       "      <td>7.360828</td>\n",
       "      <td>3.547128</td>\n",
       "      <td>3.801904</td>\n",
       "      <td>89.000162</td>\n",
       "      <td>60.271261</td>\n",
       "      <td>85.286719</td>\n",
       "      <td>22.439863</td>\n",
       "      <td>109.443074</td>\n",
       "      <td>0.059835</td>\n",
       "      <td>1.348187</td>\n",
       "      <td>0.422768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.672228e+12</td>\n",
       "      <td>-13.560601</td>\n",
       "      <td>-11.922408</td>\n",
       "      <td>-11.290123</td>\n",
       "      <td>-294.489899</td>\n",
       "      <td>-203.629913</td>\n",
       "      <td>-263.339905</td>\n",
       "      <td>-48.770995</td>\n",
       "      <td>-178.878626</td>\n",
       "      <td>-0.217041</td>\n",
       "      <td>1.163312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.672228e+12</td>\n",
       "      <td>-9.193881</td>\n",
       "      <td>-6.380931</td>\n",
       "      <td>-4.971462</td>\n",
       "      <td>-52.237481</td>\n",
       "      <td>-18.462493</td>\n",
       "      <td>-31.587489</td>\n",
       "      <td>5.498423</td>\n",
       "      <td>-81.342167</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>9.304435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.672228e+12</td>\n",
       "      <td>-4.714596</td>\n",
       "      <td>-2.927912</td>\n",
       "      <td>-0.540077</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>1.679999</td>\n",
       "      <td>1.574999</td>\n",
       "      <td>18.039351</td>\n",
       "      <td>-73.644995</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>9.860143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.672228e+12</td>\n",
       "      <td>5.555248</td>\n",
       "      <td>-0.893941</td>\n",
       "      <td>1.803450</td>\n",
       "      <td>41.264984</td>\n",
       "      <td>32.899989</td>\n",
       "      <td>54.617482</td>\n",
       "      <td>37.642082</td>\n",
       "      <td>120.324197</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>10.706850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.672228e+12</td>\n",
       "      <td>13.665982</td>\n",
       "      <td>10.650652</td>\n",
       "      <td>9.910591</td>\n",
       "      <td>298.059906</td>\n",
       "      <td>191.239929</td>\n",
       "      <td>221.689926</td>\n",
       "      <td>86.901421</td>\n",
       "      <td>179.627955</td>\n",
       "      <td>0.422607</td>\n",
       "      <td>16.474438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp           ax           ay           az           gx  \\\n",
       "count  1.366000e+03  1366.000000  1366.000000  1366.000000  1366.000000   \n",
       "mean   1.672228e+12    -2.194387    -3.651228    -1.438232    -3.102188   \n",
       "std    4.215225e+04     7.360828     3.547128     3.801904    89.000162   \n",
       "min    1.672228e+12   -13.560601   -11.922408   -11.290123  -294.489899   \n",
       "25%    1.672228e+12    -9.193881    -6.380931    -4.971462   -52.237481   \n",
       "50%    1.672228e+12    -4.714596    -2.927912    -0.540077     0.665000   \n",
       "75%    1.672228e+12     5.555248    -0.893941     1.803450    41.264984   \n",
       "max    1.672228e+12    13.665982    10.650652     9.910591   298.059906   \n",
       "\n",
       "                gy           gz        pitch         roll          BAR  \\\n",
       "count  1366.000000  1366.000000  1366.000000  1366.000000  1366.000000   \n",
       "mean      8.506637     5.378622    22.621247    -2.271998     0.023516   \n",
       "std      60.271261    85.286719    22.439863   109.443074     0.059835   \n",
       "min    -203.629913  -263.339905   -48.770995  -178.878626    -0.217041   \n",
       "25%     -18.462493   -31.587489     5.498423   -81.342167    -0.005127   \n",
       "50%       1.679999     1.574999    18.039351   -73.644995     0.019165   \n",
       "75%      32.899989    54.617482    37.642082   120.324197     0.044373   \n",
       "max     191.239929   221.689926    86.901421   179.627955     0.422607   \n",
       "\n",
       "            totacc       status  mov    prob  \n",
       "count  1366.000000  1366.000000  0.0  1366.0  \n",
       "mean      9.977873     0.232796  NaN     0.0  \n",
       "std       1.348187     0.422768  NaN     0.0  \n",
       "min       1.163312     0.000000  NaN     0.0  \n",
       "25%       9.304435     0.000000  NaN     0.0  \n",
       "50%       9.860143     0.000000  NaN     0.0  \n",
       "75%      10.706850     0.000000  NaN     0.0  \n",
       "max      16.474438     1.000000  NaN     0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression EVALUATION\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Up coefficient by Exercise Type\n",
    "Back Up coefficient data in specific exercise type name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file = open('coefficients.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Write the feature names and coefficients to the CSV file\n",
    "for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    csv_writer.writerow([feature, coef])\n",
    "# Remove square brackets from the intercept term\n",
    "intercept_str = str(model.intercept_).strip('[]')\n",
    "# Write the intercept term to the CSV file\n",
    "csv_writer.writerow(['intercept', intercept_str])\n",
    "# Close the file\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FTP\n",
    "\n",
    "# Open file in write mode\n",
    "with open('coefficients.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Iterate over features and coefficients\n",
    "    for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "        # Write feature and coefficient to file\n",
    "        writer.writerow([feature, coef])\n",
    "    # Convert intercept to string and remove brackets\n",
    "    intercept_str = str(model.intercept_)\n",
    "    intercept_str = intercept_str.strip('[]')\n",
    "    # Write intercept to file\n",
    "    writer.writerow(['intercept', intercept_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Create the CSV file\n",
    "csv_file = open('coefficients.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Write the feature names and coefficients to the CSV file\n",
    "for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    csv_writer.writerow([feature, coef])\n",
    "intercept_str = str(model.intercept_).strip('[]')\n",
    "csv_writer.writerow(['intercept', intercept_str])\n",
    "\n",
    "# Close the file\n",
    "csv_file.close()\n",
    "\n",
    "# Read the contents of the CSV file\n",
    "with open(\"coefficients.csv\", \"rb\") as file:\n",
    "    file_contents = file.read()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE CSV AND UPLOAD TO DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOGLE DRIVE AUTHENTICATION CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "creds = None\n",
    "\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    \n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERIFICA E IN CASO NEGATIVO CREA LA CARTELLA uploadpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    service = build(\"drive\", \"v3\", credentials=creds)\n",
    "    response = service.files().list(\n",
    "        q=\"name= 'wowcoeffdata' and mimeType='application/vnd.google-apps.folder'\",\n",
    "        spaces='drive'\n",
    "    ).execute()\n",
    "    if not response['files']:\n",
    "        file_metadata = {\n",
    "            \"name\": \"wowcoeffdata\",\n",
    "            \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
    "        file = service.files().create(body=file_metadata, fields=\"id\").execute()\n",
    "        folder_id = file.get('id')\n",
    "    else:\n",
    "        folder_id = response['files'][0]['id']\n",
    "except HttpError as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new text file on Google Drive\n",
    "\n",
    "#file_metadata = {\n",
    "    #'name': 'testfile.txt',\n",
    "    #'mimeType': 'text/plain',\n",
    "    #'parents': ['1RS6V6qWHL7gd1zP2GT7IKOlOPb1Y1YZt']}\n",
    "#file = service.files().create(body=file_metadata, media_body=None).execute()\n",
    "#print(F'File ID: {file.get(\"id\")}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV with features and relative coefficients and store to Google Drive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "csv_file = open('coefficients.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    csv_writer.writerow([feature, coef])\n",
    "intercept_str = str(model.intercept_).strip('[]')\n",
    "csv_writer.writerow(['intercept', intercept_str])\n",
    "csv_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if coefficient.csv file already exist than delete and upload the new one, kind of \"overwrite\" method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 1RCYPS5zFfbjSir7YSbBJGFClnnUWqwZF\n"
     ]
    }
   ],
   "source": [
    "FOLDER_ID = '1VPscx4VdYshDO-RuWZpWvtXJ760fOvPq'\n",
    "def upload_file(service, file_path, folder_id=None):\n",
    "    file_name = 'coefficients.csv'\n",
    "    query = f\"name='{file_name}' and trashed = false\"\n",
    "    if folder_id:\n",
    "        query += f\" and parents in '{folder_id}'\"\n",
    "    files = service.files().list(q=query, spaces='drive').execute()\n",
    "    existing_files = files.get('files', [])\n",
    "    for file in existing_files:\n",
    "        service.files().delete(fileId=file['id']).execute()\n",
    "\n",
    "    file_metadata = {'name': file_name, 'mimeType': 'text/csv'}\n",
    "    if folder_id:\n",
    "        file_metadata['parents'] = [folder_id]\n",
    "    media = MediaFileUpload(file_path, mimetype='text/csv', resumable=True)\n",
    "    file = service.files().create(body=file_metadata, media_body=media).execute()\n",
    "    print(F'File ID: {file.get(\"id\")}')\n",
    "upload_file(service, 'coefficients.csv', FOLDER_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ftp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ftplib\n",
    "\n",
    "# Create the CSV file\n",
    "csv_file = open('coefficients.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    csv_writer.writerow([feature, coef])\n",
    "\n",
    "intercept_str = str(model.intercept_).strip('[]')\n",
    "csv_writer.writerow(['intercept', intercept_str])\n",
    "\n",
    "\n",
    "# Read the contents of the CSV file into a variable\n",
    "csv_contents = open('coefficients.csv', 'r').read()\n",
    "\n",
    "# Remove square brackets from the intercept term\n",
    "intercept_str = str(model.intercept_).strip('[]')\n",
    "# Write the intercept term to the CSV file\n",
    "csv_writer.writerow(['intercept', intercept_str])\n",
    "\n",
    "\n",
    "\n",
    "# Connect to the FTP server\n",
    "ftp_server = ftplib.FTP('185.114.108.114')\n",
    "# Login to the FTP server\n",
    "ftp_server.login('niotron2023', 'csv_wow_2023!')\n",
    "\n",
    "\n",
    "# Open the file in binary mode\n",
    "csv_file.seek(0)\n",
    "\n",
    "# Upload the file to the FTP server\n",
    "ftp.storbinary('STOR coefficients.csv', csv_file)\n",
    "if result is None:\n",
    "    print('Error uploading file to FTP server')\n",
    "\n",
    "# Close the file and the FTP connection\n",
    "ftp.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "csv_file = open('coefficients.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "    csv_writer.writerow([feature, coef])\n",
    "intercept_str = str(model.intercept_).strip('[]')\n",
    "csv_writer.writerow(['intercept', intercept_str])\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "FOLDER_ID = '1RS6V6qWHL7gd1zP2GT7IKOlOPb1Y1YZt'\n",
    "def upload_file(service, file_path, folder_id=None):\n",
    "    file_name = 'coefficients.csv'\n",
    "    query = f\"name='{file_name}' and trashed = false\"\n",
    "    if folder_id:\n",
    "        query += f\" and parents in '{folder_id}'\"\n",
    "    files = service.files().list(q=query, spaces='drive').execute()\n",
    "    existing_files = files.get('files', [])\n",
    "    for file in existing_files:\n",
    "        service.files().delete(fileId=file['id']).execute()\n",
    "\n",
    "    file_metadata = {'name': file_name, 'mimeType': 'text/csv'}\n",
    "    if folder_id:\n",
    "        file_metadata['parents'] = [folder_id]\n",
    "    media = MediaFileUpload(file_path, mimetype='text/csv', resumable=True)\n",
    "    file = service.files().create(body=file_metadata, media_body=media).execute()\n",
    "    print(F'File ID: {file.get(\"id\")}')\n",
    "upload_file(service, 'coefficients.csv', FOLDER_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funziona ftp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ftplib\n",
    "\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "        writer.writerow([feature, coef])\n",
    "    writer.writerow(['b0', model.intercept_])\n",
    "\n",
    "\n",
    "# Connect to the FTP server\n",
    "ftp_server = ftplib.FTP('185.114.108.114')\n",
    "# Login to the FTP server\n",
    "ftp_server.login('niotron2023', 'csv_wow_2023!')\n",
    "\n",
    "\n",
    "with open('output.csv', 'rb') as f:\n",
    "    ftp_server.storbinary('STOR output.csv', f)\n",
    "ftp_server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ftplib\n",
    "\n",
    "# Open file in write mode\n",
    "with open('coefficients.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Iterate over features and coefficients\n",
    "    for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "        # Write feature and coefficient to file\n",
    "        writer.writerow([feature, coef])\n",
    "    # Convert intercept to string and remove brackets\n",
    "    b0_str = str(model.intercept_)\n",
    "    b0_str = b0_str.strip('[]')\n",
    "    # Write intercept to file\n",
    "    writer.writerow(['b0', b0_str])\n",
    "\n",
    "# Connect to FTP server\n",
    "ftp_server = ftplib.FTP('185.114.108.114')\n",
    "# Login to FTP server\n",
    "ftp_server.login('niotron2023', 'csv_wow_2023!')\n",
    "\n",
    "# Open file in binary read mode\n",
    "with open('coefficients.csv', 'rb') as f:\n",
    "    # Store file on FTP server\n",
    "    ftp_server.storbinary('STOR coefficients.csv', f)\n",
    "# Close FTP connection\n",
    "ftp_server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FTP\n",
    "\n",
    "# Open file in write mode\n",
    "with open('coefficients.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Iterate over features and coefficients\n",
    "    for feature, coef in zip(X.columns, model.coef_[0]):\n",
    "        # Write feature and coefficient to file\n",
    "        writer.writerow([feature, coef])\n",
    "    # Convert intercept to string and remove brackets\n",
    "    intercept_str = str(model.intercept_)\n",
    "    intercept_str = intercept_str.strip('[]')\n",
    "    # Write intercept to file\n",
    "    writer.writerow(['intercept', intercept_str])\n",
    "\n",
    "\n",
    "# Connect to FTP server\n",
    "ftp_server = ftplib.FTP('185.114.108.114')\n",
    "# Login to FTP server\n",
    "ftp_server.login('niotron2023', 'csv_wow_2023!')\n",
    "\n",
    "# Open file in binary read mode\n",
    "with open('coefficients.csv', 'rb') as f:\n",
    "    # Store file on FTP server\n",
    "    ftp_server.storbinary('STOR coefficients.csv', f)\n",
    "# Close FTP connection\n",
    "ftp_server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b6617685accd4af7f4132e41a63528e481eb652d27c876668ce43df200deedd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
