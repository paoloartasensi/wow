{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m fetch_california_housing\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lunghezza_albero = 100\n",
    "random_state = None ##davvero random \n",
    "# random_state = 5 ##un integer qualsiasi, prende sempre gli stessi numeri random ogni volta che lanci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/lorenzobassetti/Dropbox/Quant/Python_DEV/artabax/squat_60_sec_telefono.csv' , sep=';' , decimal='.')\n",
    "df.set_index('Time', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y è l'output che utilizziamo come training\n",
    "## X sono le feautures, BISOGNA togliere la Y dalle colonne feautures \n",
    "\n",
    "y = df['DOWN']\n",
    "X = df.copy()\n",
    "X.drop(columns=['DOWN','Mag'], axis=1, inplace=True)\n",
    "\n",
    "##Divido il campione in Train e Test\n",
    "X_train, X_test , y_train , y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=max_lunghezza_albero )\n",
    "# clf = DecisionTreeClassifier(max_depth=max_lunghezza_albero)\n",
    "# clf = DecisionTreeRegressor(ccp_alpha=0.01, max_depth=4)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "param = clf.get_params()\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = clf.score(X_train, y_train)\n",
    "precision = precision_score(y_true= y_test, y_pred=predictions)\n",
    "recall = recall_score(y_true= y_test, y_pred=predictions)\n",
    "\n",
    "print('Accuracy:  ', round(accuracy,3))\n",
    "print('Precision: ', round(precision,3))\n",
    "print('Recall:    ', round(recall,3))\n",
    "\n",
    "from sklearn import tree\n",
    "feature_names = X.columns\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "_= tree.plot_tree(clf, \n",
    "        feature_names=feature_names, \n",
    "        filled=True, fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importanza features\n",
    "feature_names = X.columns\n",
    "feature_importance = pd.DataFrame(clf.feature_importances_, index=feature_names).sort_values(0, ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "important_features = list(feature_importance[feature_importance[0]>0].index)\n",
    "feature_importance.head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y è l'output che utilizziamo come training\n",
    "## X sono le feautures, BISOGNA togliere la Y dalle colonne feautures \n",
    "\n",
    "y = df['DOWN']\n",
    "X = df.copy()\n",
    "X.drop(columns=['DOWN','Mag'], axis=1, inplace=True)\n",
    "\n",
    "##Divido il campione in Train e Test\n",
    "X_train, X_test , y_train , y_test = train_test_split(X, y, test_size=0.25, random_state=random_state)\n",
    "clr = DecisionTreeRegressor(max_depth=max_lunghezza_albero)\n",
    "clr = clr.fit(X_train, y_train)\n",
    "param = clr.get_params()\n",
    "predictions = clr.predict(X_test)\n",
    "accuracy = clr.score(X_train, y_train)\n",
    "precision = precision_score(y_true= y_test, y_pred=predictions)\n",
    "recall = recall_score(y_true= y_test, y_pred=predictions)\n",
    "\n",
    "print('Accuracy:  ', round(accuracy,3))\n",
    "print('Precision: ', round(precision,3))\n",
    "print('Recall:    ', round(recall,3))\n",
    "\n",
    "from sklearn import tree\n",
    "feature_names = X.columns\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "_= tree.plot_tree(clr, \n",
    "        feature_names=feature_names, \n",
    "        filled=True, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importanza features\n",
    "feature_names = X.columns\n",
    "feature_importance = pd.DataFrame(clr.feature_importances_, index=feature_names).sort_values(0, ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "important_features = list(feature_importance[feature_importance[0]>0].index)\n",
    "feature_importance.head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=None, solver = 'lbfgs', max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Methods we can use in Logistic\n",
    "\n",
    "# predict - Predict class labels for samples in X\n",
    "log_reg.predict(X_train)\n",
    "y_pred = log_reg.predict(X_train)\n",
    "\n",
    "# predict_proba - Probability estimates\n",
    "pred_proba = log_reg.predict_proba(X_train)\n",
    "\n",
    "# coef_ - Coefficient of the features in the decision function\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Logistic Regression EVALUATION'''\n",
    "\n",
    "# Accuracy on Train\n",
    "print(\"LogReg Training Accuracy is: \", log_reg.score(X_train, y_train))\n",
    "# Accuracy on Test\n",
    "print(\"LogReg Testing Accuracy is: \", log_reg.score(X_test, y_test))\n",
    "# Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix function\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, cmap=\"coolwarm_r\", \n",
    "                    xticklabels=classes, \n",
    "                    yticklabels=classes, \n",
    "                    vmin=0., vmax=1., \n",
    "                    annot=True, annot_kws={'size':30}\n",
    "                    )\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Visualizing cm\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "cm_norm = cm / cm.sum(axis=1).reshape(-1,1)\n",
    "\n",
    "plot_confusion_matrix(cm_norm, classes = log_reg.classes_, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating False Positives (FP), False Negatives (FN), True Positives (TP) & True Negatives (TN)\n",
    "\n",
    "FP = cm.sum(axis=0) - np.diag(cm)\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP / (TP + FN)\n",
    "print(\"The True Positive Rate is:\", TPR)\n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP / (TP + FP)\n",
    "print(\"The Precision is:\", PPV)\n",
    "\n",
    "# False positive rate or False alarm rate\n",
    "FPR = FP / (FP + TN)\n",
    "print(\"The False positive rate is:\", FPR)\n",
    "\n",
    "\n",
    "# False negative rate or Miss Rate\n",
    "FNR = FN / (FN + TP)\n",
    "print(\"The False Negative Rate is: \", FNR)\n",
    "\n",
    "\n",
    "##Total averages :\n",
    "print(\"\")\n",
    "print(\"The average TPR is:\", TPR.mean())\n",
    "\n",
    "print(\"The average Precision is:\", PPV.mean())\n",
    "print(\"The average False positive rate is:\", FPR.mean())\n",
    "print(\"The average False Negative Rate is:\", FNR.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione Lineare Multivariata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LinearRegression()\n",
    "y = df['DOWN']\n",
    "X = df.copy()\n",
    "X.drop(columns=['DOWN','Mag'], axis=1, inplace=True)\n",
    "\n",
    "mlr.fit(X, y)\n",
    "Y_hat = mlr.predict(X)\n",
    "b0 = mlr.coef_\n",
    "b1 = mlr.intercept_\n",
    "\n",
    "reg = pd.DataFrame(data =[X.columns, b0]).T\n",
    "reg.rename(columns={0:'Reg',1:'Weight'}, inplace=True)\n",
    "reg.set_index('Reg', inplace=True)\n",
    "reg.sort_values(by='Weight', key=abs, ascending=False , inplace=True)\n",
    "\n",
    "print(reg)\n",
    "print('Termine noto:',b1)\n",
    "print(' ')\n",
    "print('MLR: ', mlr.score(X, y))\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.kdeplot(data=df, x='DOWN' , label='Valori Reali')\n",
    "sns.kdeplot(Y_hat , label='Valori stimati')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
